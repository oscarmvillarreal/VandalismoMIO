--- 
title: "Análisis de Vandalismos a la Flota del SITM MIO en Cali: Importancia y Justificación"
author: "Oscar Morán - Karol Mejía"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "En este libro, exploraremos en detalle la base de datos que recopila información sobre los incidentes de vandalismo que han afectado al Sistema Integrado de Transporte Masivo (SITM) conocido como MIO. El MIO es un sistema de transporte público que opera en la ciudad de Cali, Colombia, y ha sido objeto de diversos actos de vandalismo a lo largo del tiempo. The output format for this example is bookdown::gitbook."
---

# Descripción data Vandalismo flota SITM MIO

---
title: "Análisis de Vandalismos a la Flota del SITM MIO en Cali: Importancia y Justificación"
author: "Karol Mejía - Oscar Morán"
date: "21/09/2023"
output: html_document
---

## Introducción

<p style="text-align: justify;"> El presente documento tiene como objetivo analizar la base de datos histórica de vandalismos a la flota del Sistema Integrado de Transporte Masivo (SITM) MIO en la ciudad de Cali, Colombia. La información ha sido suministrada internamente por Metro Cali, lo que garantiza el acceso a datos confiables y autorizados para su análisis. </p>

## Justificación

<p style="text-align: justify;"> El estudio de la base de datos histórica de vandalismos a la flota del SITM MIO reviste gran importancia por diversas razones:</p>

1. <p style="text-align: justify;"> **Impacto en el Transporte Público:** El vandalismo a los autobuses y estaciones del MIO puede ocasionar daños significativos, generando costos operativos adicionales para el sistema. Este análisis nos permitirá comprender la magnitud del problema y cuantificar su impacto en el transporte público de la ciudad.
</p>

2. **Seguridad Ciudadana:** Los actos de vandalismo también pueden afectar la seguridad de los usuarios y trabajadores del transporte público. Al analizar los datos, podremos identificar áreas y momentos de mayor riesgo, lo que facilitará la implementación de estrategias de prevención y protección.

3. **Toma de Decisiones:** Contar con información sólida sobre los incidentes de vandalismo permitirá a las autoridades y a Metro Cali tomar decisiones informadas y eficientes para mejorar la protección de la flota y reducir los daños.

4. **Detección de Patrones y Tendencias:** Mediante técnicas de análisis de datos, podremos identificar patrones y tendencias en los actos de vandalismo. Esto puede ser útil para anticipar futuros incidentes y diseñar políticas de prevención más efectivas.

5. **Mejora del Servicio:** Al entender mejor la naturaleza de los vandalismos, se pueden implementar estrategias para minimizar los tiempos de inactividad de la flota y mejorar la calidad del servicio ofrecido a los usuarios.</p>

## Fuentes y Permisos de Uso

<p style="text-align: justify;"> La información utilizada en este análisis proviene de la base de datos suministrada internamente por Metro Cali. Se ha obtenido el permiso explícito para utilizar estos datos con fines analíticos y académicos, garantizando la confidencialidad y protección de la información sensible.</p>

# Estructura de los datos en series de tiempo

<p style="text-align: justify;"> La estructura de los datos en series de tiempo es fundamental para el análisis y modelado adecuados de los patrones temporales en los datos. Los datos de serie de tiempo son observaciones registradas en momentos específicos a lo largo del tiempo.</p>

<p style="text-align: justify;"> En el presente cápitulo abordaremos el análisis de la información contenida en la base de datos de vandalismos suministrada por el ente gestor del sistema de transporte masivo MIO, con el fin de verificar en primera instancia los valores contenidos, información relevante y estructura del dataset.</p>

<p style="text-align: justify;"> La estructura de los datos en series de tiempo se basa en la secuencia temporal de observaciones de una variable específica. Entender esta estructura es esencial para aplicar técnicas de análisis y modelado de series de tiempo de manera efectiva.</p>



```{r setup, include=FALSE, echo=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(dplyr)
library(knitr)
library(ggplot2)
library(readxl)
library(lubridate)
library(fpp2)
library(zoo)
library(TTR)
library(tseries)
library(aTSA)
library(forecast)
library(ADGofTest)
library(lmtest)
```

<p style="text-align: justify;"> Comenzamos el proceso al acceder a la base de datos de vandalismos, que  contiene información correspondiente de vandalismos a la flota del SITM MIO de los años 2021 y 2022.</p>

```{r, warning=FALSE}
vandalismo <- read_excel("vandalismo.xlsx")
```

## Aproximación en promedio Móvil

<p style="text-align: justify;"> En el análisis de series temporales, el método de medias móviles tiene variadas aplicaciones, así, este método puede sernos útil si queremos calcular la tendencia de la serie temporal sin tener que ajustarnos a una función previa, ofreciendo así una visión suavizada de una serie, ya que promediando varios valores se elimina parte de los movimientos irregulares de la serie; también puede servirnos para realizar predicciones cuando la tendencia de la serie tiene una media constante.</p>

<p style="text-align: justify;"> Permite observar y resaltar tendencias subyacentes o patrones cíclicos al calcular el promedio de un conjunto de valores en un intervalo móvil de tiempo, por lo que esta técnica es especialmente útil para eliminar el ruido y las fluctuaciones aleatorias en los datos, lo que puede hacer que los patrones temporales sean más visibles.</p>

<p style="text-align: justify;"> A continuación, se presenta el proceso de estructuración de la secuencia del conjunto de datos con el objetivo de identificar las fechas relevantes y determinar la columna base necesaria para la posterior creación de una gráfica de serie, en el fragmento de código en lenguaje R que sigue, se ilustra cómo se lleva a cabo esta tarea:</p>

```{r}
Fecha <- seq(as.Date("2021-01-01"), as.Date("2022-10-26"), by = "days", each = 1) 
datos_sumados <- aggregate(Calificación ~ Fecha, data = vandalismo, sum)
```
<p style="text-align: justify;"> En este fragmento, se procede a generar una secuencia de fechas de acuerdo a la información revisada incialmente al llamar el dataset, abarca desde enero de 2021 hasta octubre de 2022 con una frecuencia diaria.</p>

<p style="text-align: justify;"> Se plantea a continuación como objetivo proporcionar una visualización gráfica de los datos en bruto contenidos en el conjunto de datos,esto se realiza para obtener una representación visual que permita identificar patrones y tendencias en las variables involucradas.</p>

```{r, fig.width=20, fig.height=5}
grafico <- ggplot(datos_sumados, aes(x = Fecha, y = Calificación)) +
  geom_line() +    # Línea para conectar los puntos
  geom_point() +   # Puntos en cada fecha
  labs(x = "Fecha", y = "Número de Casos", title = "Casos de Vandalismo por Fecha") +
  theme_bw()
print(grafico)
```

<p style="text-align: justify;"> Procederemos a calcular el promedio móvil de la columna "Calificación" en un intervalo específico dentro del período desde enero de 2021 hasta octubre de 2022.</p>


```{r}
# Función de promedio móvil en un intervalo
promedio_movil <- function(datos_sumados, Calificación, intervalo) {
  datos_sumados %>%
    mutate(promedio = rollmean(Calificación, intervalo, fill = NA))
}
```
<p style="text-align: justify;"> La función rollmean() se aplica a la columna "Calificación" con el intervalo especificado, calculando así el promedio móvil.</p>

```{r}
# Calcular promedio móvil con intervalo de 7 días
data_con_promedio <- promedio_movil(datos_sumados, "Calificación", 7)
knitr::kable(head(data_con_promedio, 50), caption = "Base de Datos Vandalismos FLOTA")
#data_con_promedio
```


<p style="text-align: justify;"> A continuación, se presenta el proceso de creación de la visualización en gráfica que incorpora tanto los valores originales de una columna como su respectivo promedio móvil, esta representación permite observar de manera efectiva cómo fluctúan los datos en relación con su tendencia promedio en un intervalo de tiempo de 7 días.</p> 

```{r, fig.width=20, fig.height=5, warning=FALSE}
# Gráfico de Aproximación en Promedio Móvil
ggplot() +
  geom_line(data = datos_sumados, aes(x = Fecha, y = Calificación), color = "blue", linetype = "solid") +
  geom_line(data = data_con_promedio, aes(x = Fecha, y = promedio), color = "red", linetype = "dashed") +
  labs(title = "Aproximación en Promedio Móvil", x = "Fecha", y = "Valor") +
  theme_minimal()
```


<p style="text-align: justify;"> A continuación se presenta una función esencial en el análisis de series temporales, enfocada en calcular los rezagos de una variable en un conjunto de datos, en el ámbito del análisis de series temporales, el cálculo de rezagos desempeña un papel crucial para comprender las relaciones entre observaciones pasadas y presentes en una secuencia temporal.</p>}

## Calculo de los rezagos

```{r}

calcular_rezagos <- function(datos_sumados, Calificación, pasos) {
  datos_sumados %>%
    mutate(across(.cols = Calificación, .fns = list(lag = ~lag(., pasos)), .names = "{col}_lag{pasos}"))
}
```
<p style="text-align: justify;"> Se inicia calculando los rezagos de 7 días en la columna "Calificación" del conjunto de datos "datos_sumados", posteriormente se calculan los rezagos de 7 días en la columna "Calificación_lag7", que ya contiene los rezagos de 7 días calculados en la etapa anterior; esto permite obtener los rezagos de 14 días.</p>

<p style="text-align: justify;"> Esta estrategia de calcular rezagos en etapas sucesivas es útil para analizar efectos a más largo plazo en la serie temporal.</p>


```{r}
# Calcular rezagos de 7 y 14 días 
data_con_rezagos <- calcular_rezagos(datos_sumados, "Calificación", 7)
data_con_rezagos <- calcular_rezagos(data_con_rezagos, "Calificación_lag7", 7)
```

```{r}
names(data_con_rezagos)
```
<p style="text-align: justify;"> Se procede a realizar un gráfico que permite comparar los valores originales de una serie temporal con los rezagos de 7 días correspondientes. </p>

```{r, fig.width=10, fig.height=5, warning=FALSE}
ggplot(data_con_rezagos, aes(x = Fecha)) +
  geom_line(aes(y = Calificación, color = "black")) +
  geom_line(aes(y = Calificación_lag7, color = "red")) +
  labs(title = "Gráfico de Rezagos",
       y = "Calificación",
       color = "Leyenda") +
  scale_color_manual(values = c("Valor original" = "black",
                                "Rezago 7 días" = "red")) +
  theme_minimal()
```

<p style="text-align: justify;"> Procedemos crear un gráfico consolidado que permite comparar visualmente múltiples aspectos:</p>

<p style="text-align: justify;"> 1. Con "geom_line", se agregan varias capas de líneas al gráfico:</p>
<p style="text-align: justify;"> -La primera línea representa los valores originales de la columna "Calificación" en color azul y con línea sólida.</p>
<p style="text-align: justify;"> -La segunda línea representa los valores del promedio móvil en color rojo y con línea punteada.</p>
<p style="text-align: justify;"> -Las dos siguientes líneas representan los valores originales y los rezagos de 7 días en color verde y naranja, respectivamente,ambas con línea punteada de una serie temporal a lo largo del tiempo.</p>

## Graficar los resultados Promedio y Rezagos

```{r, fig.width=10, fig.height=5, warning=FALSE}
# Graficar los resultados
ggplot() +
  geom_line(data = data_con_rezagos, aes(x = Fecha, y = Calificación), color = "green", linetype = "dotted") +
  geom_line(data = data_con_rezagos, aes(x = Fecha, y = Calificación_lag7), color = "orange", linetype = "dotted") +
  geom_line(data = datos_sumados, aes(x = Fecha, y = Calificación), color = "blue", linetype = "solid") +
  geom_line(data = data_con_promedio, aes(x = Fecha, y = promedio), color = "red", linetype = "dashed") +
  labs(title = "Análisis de Variable en el Tiempo", x = "Fecha", y = "Calificación") +
  theme_minimal()
```


# Preprocesamiento y visualización  

<p style="text-align: justify;"> A continuación se realizará un proceso determinante que nos permitirá definir y explicar los componentes fundamentales que componen nuestra serie a lo largo del tiempo, al separar la serie en sus partes constituyentes, como la tendencia, la estacionalidad y el componente residual, se comprende mejor los patrones y las variaciones presentes.</p>

## Descomposición de la serie de tiempo

```{r}
# Realizar descomposición de la serie de tiempo
serie_de_tiempo <- ts(datos_sumados$Calificación, frequency = 240)
descomposicion <- decompose(serie_de_tiempo)
```


```{r}
# Gráfico de la descomposición
plot(descomposicion)
```

<p style="text-align: justify;"> Se procede a realizar una verificación muy necesaria para el análisis de nuestra serie de tiempo: la estacionalidadm  usaremos la biblioteca "tseries" y su prueba de Dickey-Fuller aumentada (ADF) para determinar si nuestra serie de tiempo cumple con este requisito.</p>

## Verificación Estacionalidad


```{r, warning=FALSE}
# Verificar estacionalidad
adf_test <- adf.test(datos_sumados$Calificación)
print(adf_test)
 
```
<p style="text-align: justify;"> El valor p (0.01 en este caso) es menor que el nivel comúnmente utilizado de 0.05, lo que indica que se rechaza la hipótesis nula. La hipótesis nula en este caso es que la serie de tiempo tiene una raíz unitaria y no es "estacionaria", dado que el valor p es pequeño, se puede concluir que hay suficiente evidencia estadística para decir que la serie de tiempo es estacionaria en función de los resultados de la prueba ADF, gracias a la estacionariedad de la serie, evitaremos la necesidad de realizar diferenciación en este caso particular.</p>


# Modelado Serie Suavización Exponencial y Métodos

<p style="text-align: justify;"> En este capítulo, se abordará el análisis y modelado de una serie de tiempo utilizando dos enfoques ampliamente utilizados: la suavización exponencial y el método de Holt-Winters.</p>

<p style="text-align: justify;"> Estos métodos son herramientas valiosas en el campo del análisis de series temporales y permiten capturar y predecir patrones en los datos a lo largo del tiempo.</p>

<p style="text-align: justify;"> Examinemos el enfoque de modelado de esta serie temporal mediante una regresión lineal. </p>

```{r, fig.width=10, fig.height=5, warning=FALSE}
plot(serie_de_tiempo)
abline(reg = lm(serie_de_tiempo ~ time(serie_de_tiempo)))

```

## Método Suavización Exponencial

<p style="text-align: justify;"> Aunque de acuerdo al criterio de la prueba prueba de Dickey-Fuller aumentada (ADF), la serie de tiempo es estacionaria y no muestra una tendencia o componente estacional, es posible que el método de Suavización Exponencial Simple no sea útil en este contexto</p>


```{r}
# Aplicar suavizamiento exponencial simple
modelo_suavizado <- HoltWinters(serie_de_tiempo, beta = FALSE, gamma = FALSE)
modelo_suavizado

```



```{r, fig.width=10, fig.height=5, warning=FALSE}
Suav_exp <- ses(serie_de_tiempo, h = 15)
autoplot(Suav_exp) + autolayer(fitted(Suav_exp), series="Fitted")
```


<p style="text-align: justify;"> Después de aplicar el método de suavización exponencial a los datos, se llega a la conclusión de que este enfoque no logra capturar de manera efectiva una tendencia estacional presente en los datos, a pesar de tener la capacidad de detectar patrones a lo largo del tiempo, el método de suavización exponencial parece no ser adecuado para identificar y modelar la variabilidad estacional que puede influir en la serie temporal en consideración. La naturaleza de los datos parece no alinearse de manera óptima con las premisas y el enfoque del método de suavización exponencial en relación con la tendencia estacional, por lo tanto, es necesario explorar alternativas más apropiadas y específicas para abordar esta característica particular de la serie de tiempo.</p>


## Metodología Holter-Winter y de suavizamiento 


```{r}
# Instalar y cargar el paquete de suavizamiento exponencial
library(forecast)
```

```{r}
# Crear una serie de tiempo con frecuencia diaria
serie_tiempof <- ts(datos_sumados$Calificación, frequency = 2)
```


<p style="text-align: justify;"> La metodología Holt-Winters es un enfoque de pronóstico de series de tiempo que incorpora componentes de nivel, tendencia y estacionalidad para mejorar la precisión de las predicciones. Los tres componentes que considera son:
</p>

<p style="text-align: justify;"> - **Componente de nivel (nivel):** El nivel representa el valor medio de la serie de tiempo en un período dado. Se calcula utilizando el suavizamiento exponencial simple.
</p>

<p style="text-align: justify;"> - **Componente de tendencia (tendencia):** La tendencia se refiere a la dirección y magnitud del cambio en la serie de tiempo. Se calcula utilizando el suavizamiento exponencial doble.
</p>

<p style="text-align: justify;"> - **Componente estacional (estacionalidad):** La estacionalidad se refiere a las fluctuaciones regulares en la serie de tiempo debido a patrones estacionales. Se incorpora mediante el suavizamiento exponencial triple, que considera tanto la estacionalidad como la tendencia.
</p>

<p style="text-align: justify;"> La metodología Holt-Winters se adapta bien a series de tiempo que tienen tendencias y patrones estacionales. Esta técnica utiliza los valores históricos para calcular las estimaciones de los tres componentes y luego los combina para realizar pronósticos futuros.
</p>

```{r, fig.width=10, fig.height=5, warning=FALSE}
mod1 <- HoltWinters(serie_tiempof, seasonal = "additive")
plot(mod1)
```
```{r}
mod1
```



```{r}
adf.test(diff(serie_tiempof))
```

<p style="text-align: justify;"> Al aplicar el Método Holt-Winters a nuestros datos de la serie temporal, podemos destacar observar patrones estacionales, a diferencia del enfoque de suavización exponencial, que no logró reflejar las variaciones estacionales, este Método Holt-Winters es efectivo en este sentido.  El Método Holt-Winters resulta ser una herramienta útil para abordar tendencias estacionales en series temporales, ofreciendo resultados sólidos y precisos en la modelación de estos patrones.  
</p>

# Método Box-Jenkins Modelo ARIMA


<p style="text-align: justify;"> En el mundo del análisis de series de tiempo, el descubrimiento y la comprensión de patrones temporales son cruciales para tomar decisiones informadas, una de las técnicas más poderosas en este campo es la metodología ARIMA (Autoregressive Integrated Moving Average).</p>


## ¿Por qué ARIMA para datos estacionales?

<p style="text-align: justify;"> Cuando trabajamos con series de tiempo, es probable encontrar datos que permiten observar patrones recurrentes en momentos del año, del mes o incluso del día; estos patrones estacionales pueden deberse a factores como estacionalidad o tendencias de comportamiento humano estacionales. </p>

<p style="text-align: justify;"> Para modelar y predecir de manera efectiva en tales casos, esta metodología es capaz de capturar estos patrones de estacionalidad.</p>


<p style="text-align: justify;"> Se calculó el Augmented Dickey-Fuller Test a la serie de tiempo con la suavización exponencial aplicando metodología Holter Winter, en la cual se evidenvia que el p-valor es tan bajo como 0.01, confirmamos entonces que la serie de tiempo ya se encuentra en un estado estacionario,  resultado fundamental para aplicar con precisión modelos de series de tiempo como ARIMA.</p>

```{r}
adf.test(diff(serie_tiempof))
```
<p style="text-align: justify;"> Como se mencionó anteriormente según la prueba DFT, la series es estacionaria y se procede a determinar los parámetros ARIMA</p>


```{r}
modeloARIMA<-auto.arima(diff(serie_tiempof),  seasonal = FALSE)
summary(modeloARIMA) 
```


<p style="text-align: justify;"> Se procede a ajustar un modelo ARIMA a una serie de tiempo y se define el order del párametro c(p,d,q), Orden de Diferenciación (d) (ya es estacionaria, d=0), Orden de Autoregresión (p y q= valor seleccionado basándose en el último rezago significativo).</p>


```{r}
modelo_ARIMA <- arima(diff(serie_tiempof), order = c(0,0,2))
n_predicciones <- 10
modpredicciones <- predict(modelo_ARIMA, n.ahead = n_predicciones)
```

## Predicción Modelo ARIMA

<p style="text-align: justify;">  Luego de definido el modelo ARIMA para realizar predicciones, el siguiente paso es visualizar y evaluar la continuidad de las predicciones en relación con los datos reales, la visualización es una parte esencial del proceso de modelado de series de tiempo, ya que nos permite comprender si el modelo está capturando adecuadamente los patrones en los datos y si las predicciones son coherentes con el comportamiento histórico de la serie.</p>

```{r, fig.width=10, fig.height=5, warning=FALSE}

plot(diff(serie_tiempof) , main = "Serie Temporal predicción")
lines(modpredicciones$pred, col = "red", lty = 4)  # Línea de predicción
legend("topright", legend = "Predicción", col = "red", lty = 4)
```

<p style="text-align: justify;">  Realizamos un zoom a la predicción y comparamos con otro periodo para obervar similitud.</p>

```{r}
inicio_zoom <- 300
fin_zoom <- 350
plot(diff(serie_tiempof), main = "Zoom Serie Temporal predicción", xlim = c(inicio_zoom, fin_zoom))
lines(modpredicciones$pred[inicio_zoom:fin_zoom], col = "red", lty = 4)
legend("topright", legend = "Predicción", col = "red", lty = 4)
```
```{r}
inicio_zoom <- 292
fin_zoom <- 299
plot(diff(serie_tiempof), main = "Zoom Serie Temporal sin predicción", xlim = c(inicio_zoom, fin_zoom))
lines(modpredicciones$pred[inicio_zoom:fin_zoom], col = "red", lty = 4)
legend("topright", legend = "Predicción", col = "red", lty = 4)
```

<p style="text-align: justify;">  Observamos que la serie de tiempo no se ajusta bien a un modelo autorregresivo.  la efectividad de un modelo autorregresivo depende en gran medida de la calidad de los datos y de la elección de los parámetros del modelo. Si la serie de tiempo tiene una estructura compleja o no es adecuada para un modelo autorregresivo, los pronósticos pueden ser imprecisos o incluso constantes si el modelo no puede capturar adecuadamente los patrones temporales.</p>


## Comparativo Serie de Tiempo suavizada - Modelo ARIMA


```{r, fig.width=10, fig.height=5, warning=FALSE}
plot(diff(serie_tiempof), main = "Serie Tiempo suavizada Winter Holters vs. Modelo ARIMA")
lines(fitted(modelo_ARIMA), col = "green",  lwd = 0.5)
```
<p style="text-align: justify;">  Se enfatiza que la serie es estacionaria y se menciona que el modelo parece adaptarse adecuadamente a la serie sin tendencia evidente, mientras se reconoce que aún no se han definido medidas de desempeño específicas.</p>

## Comprobaciones Modelo ARIMA

<p style="text-align: justify;"> Procedemos a realizar 3 comprobaciones del modelo ARIMA, evaluando la válidez del modelo y la calidad de las predicciones.

- **Distribución de los errores:** Los modelos ARIMA asumen que los residuales siguen una distribución normal, si los residuales no siguen una distribución normal, esto puede afectar la precisión de las estimaciones de parámetros y las pruebas de significancia. También puede influir en la confiabilidad de las predicciones y en la interpretación de los resultados.

- **Independencia de los Residuales:** La independencia de los residuales es esencial, si los residuales están correlacionados en el tiempo, indica que el modelo no ha capturado completamente la estructura temporal de los datos; llevando a inferencias erróneas y predicciones inexactas.

- **Homocedasticidad de los Residuales:** La homocedasticidad significa que la varianza de los residuales es constante a lo largo del tiempo, esto es importante porque garantiza que los errores tengan la misma "dispersión" en toda la serie temporal. Cuando los residuales son heterocedásticos , las predicciones pueden ser inexactas debido a la variabilidad no constante de los errores.</p>

<p style="text-align: justify;"> Estas pruebas ayudan a verificar si se cumplen las suposiciones fundamentales del modelo y, si no se cumplen, pueden indicar la necesidad de ajustar el modelo, transformar los datos o considerar enfoques alternativos para mejorar la calidad de las predicciones y análisis de series temporales.</p>


<p style="text-align: justify;"> Procedemos a determinar los residuales del modelo ARIMA y determinar la hipotesis que permite evaluar la estacionariedad de la serie</p>

### Normalidad ARIMA

```{r}
residuales<-modelo_ARIMA$residuals
qqnorm(residuales)
qqline(residuales)
```


```{r}
resultado <- ks.test(residuales, "pnorm", mean(residuales), sd(residuales))
print(resultado)
```

<p style="text-align: justify;">  En este caso, 0,00719 significa que el valor p es extremadamente cercano a cero, un valor p tan pequeño indica una evidencia estadística muy sólida para rechazar la hipótesis nula; esto indicaría que la serie de tiempo es muy probablemente estacionaria en lugar de no estacionaria.</p>


### Independencia

<p style="text-align: justify;"> Calcular y verificar la independencia de los datos es esencial al trabajar con modelos ARIMA para garantizar que se cumplan las suposiciones fundamentales del modelo, esto contribuye a la precisión de las predicciones, la interpretación de los resultados y la confiabilidad del análisis de series temporales en general.</p>

HO: Los residuales son independientes

H1: Los residuales son dependientes 

```{r}
shapiro.test(residuales)
```
<p style="text-align: justify;">Dado que el valor p (p-value) es extremadamente bajo (6.196e-10), mucho menor que un nivel de significancia típico como 0.05, se rechaza la hipótesis nula (H0), los residuales son dependientes, </p>


<p style="text-align: justify;"> Procedemos a definir el tercer criterio de Homocedasticidad </p> 

### Homocedastidad
```{r}
# Obtén los residuales del modelo ARIMA (reemplaza 'modelo_arima' con tu propio modelo)
residuales <- residuals(modelo_ARIMA)

# Crea un gráfico de dispersión de residuales vs. tiempo
plot(residuales, type = 'o', ylab = 'Residuales', xlab = 'Tiempo', main = 'Gráfico de Residuales')
abline(h = 0, col = 'red', lty = 2)  # Línea horizontal en y = 0

```

<p style="text-align: justify;"> Mediante el método de gráfico de dispersión de los residuales al parecer existe Homocedasticidad, puesto que los puntos están dispersos aleatoriamente alrededor de una línea horizontal en el gráfico.</p>


# Prophet

<p style="text-align: justify;"> Prophet es un poderoso algoritmo de predicción desarrollado por Facebook que se utiliza ampliamente en el análisis de series de tiempo, su enfoque se basa en descomponer las series temporales en tres componentes principales: tendencia, estacionalidad y días festivos. Esto facilita la modelización de patrones complejos y la generación de pronósticos precisos. Prophet es especialmente útil cuando se trabaja con datos de series de tiempo que pueden tener tendencias no lineales y efectos de estacionalidad irregulares. Además, con Prophet, es posible realizar pronósticos precisos y tomar decisiones informadas.</p>

## Modelo

El modelo subyacente es el propuesto por Harvey & Peters (1990):

y(t)=g(t)+s(t)+h(t)+ϵt

df: dataframe
growth: tipo de tendencia: lineal o logistica
yearly.seasonality: hay estacionalidad anual?
yearly.seasonality: hay estacionalidad diaria?
holidays: dataframe con fechas de vacaciones/eventos especiales

<p style="text-align: justify;"> A continuación, cargaremos las siguientes librerías necesarias para utilizar el algoritmo Prophet:</p>

```{r, message=FALSE}
library(prophet) 
library(Rcpp)
library(rlang)
```

<p style="text-align: justify;"> Generamos la data del promedio de suavización exponencial</p>

```{r}
head(data_con_promedio, n = 20)
```

<p style="text-align: justify;"> Se crea un nuevo DataFrame llamado new_dataprom seleccionando solo las columnas 'Fecha' y 'promedio' del DataFrame original data_con_promedio.  Se renombran las columnas del DataFrame new_dataprom. La columna 'Fecha' se renombra como 'ds' y la columna 'promedio' se renombra como 'y'. Esto sugiere que los datos se están preparando para ser utilizados con el algoritmo Prophet de predicción de series de tiempo de Facebook, ya que Prophet espera que las columnas que contienen la fecha y el valor objetivo se llamen 'ds' y 'y', respectivamente. Este código facilita la preparación de datos para su uso con Prophet, una herramienta de pronóstico de series de tiempo, asegurando que los datos estén en el formato adecuado antes de aplicar el algoritmo. </p>

```{r}
new_dataprom <- data_con_promedio[c('Fecha', 'promedio')]
colnames(new_dataprom) <- c('ds', 'y')
# ------------
# df <- data.frame(datos_sumados)
# colnames(df) <- c('ds', 'y')
datos_sumados_a <- new_dataprom
head(datos_sumados_a, n=20)
```

<p style="text-align: justify;"> Se procede a realizar el siguiente modelo configurado para tener una estacionalidad anual con 13 términos (para adaptarse a patrones anuales), mientras que se deshabilita la estacionalidad semanal y diaria; Además, se establece el modo de estacionalidad en 'additive', lo que significa que el modelo asume que las estacionalidades se suman de manera lineal a la tendencia. Por otro lado, se generan 2 años (2*365 días) de fechas futuras con una frecuencia diaria ('day') en función de la información proporcionada por el modelo m.</p>

<p style="text-align: justify;"> Por último, se genera un gráfico que muestra tanto los datos originales como las predicciones del modelo m. Esto ayuda a visualizar cómo se comparan las predicciones del modelo con los datos históricos. La función theme_bw() se utiliza para aplicar un tema de gráfico en blanco y negro.</p>

```{r, fig.width=20}
m <- prophet(datos_sumados_a, yearly.seasonality = 13, weekly.seasonality = FALSE, daily.seasonality = FALSE, seasonality.mode = 'additive')
future <- make_future_dataframe(m, periods = 2*365, freq = 'day')
forecast <- predict(m, future)
plot(m, forecast)  + theme_bw()
```

```{r, fig.width=20}
prophet_plot_components(m, fcst=predict(m, datos_sumados_a)) + theme_bw()
```

<p style="text-align: justify;"> Se evidencia una coherencia notoria en el pronóstico, ya que la incidencia de vandalismo en el sistema de transporte MIO muestra una clara relación con la temporada del año. Durante los meses de junio a agosto, así como en diciembre, se observa una disminución pronunciada en las proyecciones de vandalismo. Al utilizar Prophet, hemos podido obtener una visión más clara de cómo se comportarán los datos en el futuro, lo que puede ser muy beneficioso para la toma de decisiones y la planificación estratégica, la capacidad de Prophet para generar intervalos de confianza también brinda una idea de la incertidumbre asociada con las predicciones, lo que permite una toma de decisiones más informada.</p>

