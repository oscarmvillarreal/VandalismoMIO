mutate(across(.cols = Calificación, .fns = list(lag = ~lag(., pasos)), .names = "{col}_lag{pasos}"))
}
# Calcular rezagos de 7 y 14 días
data_con_rezagos <- calcular_rezagos(datos_sumados, "Calificación", 7)
data_con_rezagos <- calcular_rezagos(data_con_rezagos, "Calificación_lag7", 7)
names(data_con_rezagos)
ggplot(data_con_rezagos, aes(x = Fecha)) +
geom_line(aes(y = Calificación, color = "black")) +
geom_line(aes(y = Calificación_lag7, color = "red")) +
labs(title = "Gráfico de Rezagos",
y = "Calificación",
color = "Leyenda") +
scale_color_manual(values = c("Valor original" = "black",
"Rezago 7 días" = "red")) +
theme_minimal()
# Graficar los resultados
ggplot() +
geom_line(data = datos_sumados, aes(x = Fecha, y = Calificación), color = "blue", linetype = "solid") +
geom_line(data = data_con_promedio, aes(x = Fecha, y = promedio), color = "red", linetype = "dashed") +
geom_line(data = data_con_rezagos, aes(x = Fecha, y = Calificación), color = "green", linetype = "dotted") +
geom_line(data = data_con_rezagos, aes(x = Fecha, y = Calificación_lag7), color = "orange", linetype = "dotted") +
labs(title = "Análisis de Variable en el Tiempo", x = "Fecha", y = "Calificación") +
theme_minimal()
# Realizar descomposición de la serie de tiempo
serie_de_tiempo <- ts(datos_sumados$Calificación, frequency = 240)
descomposicion <- decompose(serie_de_tiempo)
# Gráfico de la descomposición
plot(descomposicion)
# Verificar estacionalidad
adf_test <- adf.test(datos_sumados$Calificación)
print(adf_test)
plot(serie_de_tiempo)
abline(reg = lm(serie_de_tiempo ~ time(serie_de_tiempo)))
# Aplicar suavizamiento exponencial simple
modelo_suavizado <- HoltWinters(serie_de_tiempo, beta = FALSE, gamma = FALSE)
modelo_suavizado
Suav_exp <- ses(serie_de_tiempo, h = 15)
autoplot(Suav_exp) + autolayer(fitted(Suav_exp), series="Fitted")
# Instalar y cargar el paquete de suavizamiento exponencial
library(forecast)
# Crear una serie de tiempo con frecuencia diaria
serie_tiempof <- ts(datos_sumados$Calificación, frequency = 2)
mod1 <- HoltWinters(serie_tiempof, seasonal = "additive")
plot(mod1)
adf.test(diff(serie_tiempof))
adf.test(diff(serie_tiempof))
modeloARIMA<-auto.arima(diff(serie_tiempof),  seasonal = FALSE)
summary(modeloARIMA)
modelo_ARIMA <- arima(diff(serie_tiempof), order = c(0,0,2))
n_predicciones <- 10
modpredicciones <- predict(modelo_ARIMA, n.ahead = n_predicciones)
plot(diff(serie_tiempof) , main = "Serie Temporal predicción")
lines(modpredicciones$pred, col = "red", lty = 4)  # Línea de predicción
legend("topright", legend = "Predicción", col = "red", lty = 4)
inicio_zoom <- 300
fin_zoom <- 305
plot(diff(serie_tiempof), main = "Zoom Serie Temporal predicción", xlim = c(inicio_zoom, fin_zoom))
lines(modpredicciones$pred[inicio_zoom:fin_zoom], col = "red", lty = 4)
legend("topright", legend = "Predicción", col = "red", lty = 4)
inicio_zoom <- 292
fin_zoom <- 299
plot(diff(serie_tiempof), main = "Zoom Serie Temporal sin predicción", xlim = c(inicio_zoom, fin_zoom))
lines(modpredicciones$pred[inicio_zoom:fin_zoom], col = "red", lty = 4)
legend("topright", legend = "Predicción", col = "red", lty = 4)
plot(diff(serie_tiempof), main = "Serie Tiempo suavizada Winter Holters vs. Modelo ARIMA")
lines(fitted(modelo_ARIMA), col = "green",  lwd = 0.5)
residuales<-modelo_ARIMA$residuals
qqnorm(residuales)
qqline(residuales)
resultado <- ks.test(residuales, "pnorm", mean(residuales), sd(residuales))
print(resultado)
shapiro.test(residuales)
# Obtén los residuales del modelo ARIMA (reemplaza 'modelo_arima' con tu propio modelo)
residuales <- residuals(modelo_ARIMA)
# Crea un gráfico de dispersión de residuales vs. tiempo
plot(residuales, type = 'o', ylab = 'Residuales', xlab = 'Tiempo', main = 'Gráfico de Residuales')
abline(h = 0, col = 'red', lty = 2)  # Línea horizontal en y = 0
library(prophet)
library(Rcpp)
library(rlang)
df <- data.frame(datos_sumados)
colnames(df) <- c('ds', 'y')
df
m <- prophet(df)
future <- make_future_dataframe(m, periods = 365)
tail(future)
forecast <- predict(m, future)
tail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])
plot(m, forecast)
prophet_plot_components(m, forecast)
dyplot.prophet(m, forecast)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(knitr)
library(ggplot2)
library(readxl)
library(lubridate)
library(fpp2)
library(zoo)
library(TTR)
library(tseries)
library(aTSA)
library(forecast)
library(ADGofTest)
library(lmtest)
vandalismo <- read_excel("vandalismo.xlsx")
Fecha <- seq(as.Date("2021-01-01"), as.Date("2022-10-26"), by = "days", each = 1)
datos_sumados <- aggregate(Calificación ~ Fecha, data = vandalismo, sum)
grafico <- ggplot(datos_sumados, aes(x = Fecha, y = Calificación)) +
geom_line() +    # Línea para conectar los puntos
geom_point() +   # Puntos en cada fecha
labs(x = "Fecha", y = "Número de Casos", title = "Casos de Vandalismo por Fecha") +
theme_bw()
print(grafico)
# Función de promedio móvil en un intervalo
promedio_movil <- function(datos_sumados, Calificación, intervalo) {
datos_sumados %>%
mutate(promedio = rollmean(Calificación, intervalo, fill = NA))
}
# Calcular promedio móvil con intervalo de 7 días
data_con_promedio <- promedio_movil(datos_sumados, "Calificación", 7)
knitr::kable(head(data_con_promedio, 50), caption = "Base de Datos Vandalismos FLOTA")
#data_con_promedio
# Gráfico de Aproximación en Promedio Móvil
ggplot() +
geom_line(data = datos_sumados, aes(x = Fecha, y = Calificación), color = "blue", linetype = "solid") +
geom_line(data = data_con_promedio, aes(x = Fecha, y = promedio), color = "red", linetype = "dashed") +
labs(title = "Aproximación en Promedio Móvil", x = "Fecha", y = "Valor") +
theme_minimal()
calcular_rezagos <- function(datos_sumados, Calificación, pasos) {
datos_sumados %>%
mutate(across(.cols = Calificación, .fns = list(lag = ~lag(., pasos)), .names = "{col}_lag{pasos}"))
}
# Calcular rezagos de 7 y 14 días
data_con_rezagos <- calcular_rezagos(datos_sumados, "Calificación", 7)
data_con_rezagos <- calcular_rezagos(data_con_rezagos, "Calificación_lag7", 7)
names(data_con_rezagos)
ggplot(data_con_rezagos, aes(x = Fecha)) +
geom_line(aes(y = Calificación, color = "black")) +
geom_line(aes(y = Calificación_lag7, color = "red")) +
labs(title = "Gráfico de Rezagos",
y = "Calificación",
color = "Leyenda") +
scale_color_manual(values = c("Valor original" = "black",
"Rezago 7 días" = "red")) +
theme_minimal()
# Graficar los resultados
ggplot() +
geom_line(data = datos_sumados, aes(x = Fecha, y = Calificación), color = "blue", linetype = "solid") +
geom_line(data = data_con_promedio, aes(x = Fecha, y = promedio), color = "red", linetype = "dashed") +
geom_line(data = data_con_rezagos, aes(x = Fecha, y = Calificación), color = "green", linetype = "dotted") +
geom_line(data = data_con_rezagos, aes(x = Fecha, y = Calificación_lag7), color = "orange", linetype = "dotted") +
labs(title = "Análisis de Variable en el Tiempo", x = "Fecha", y = "Calificación") +
theme_minimal()
# Realizar descomposición de la serie de tiempo
serie_de_tiempo <- ts(datos_sumados$Calificación, frequency = 240)
descomposicion <- decompose(serie_de_tiempo)
# Gráfico de la descomposición
plot(descomposicion)
# Verificar estacionalidad
adf_test <- adf.test(datos_sumados$Calificación)
print(adf_test)
plot(serie_de_tiempo)
abline(reg = lm(serie_de_tiempo ~ time(serie_de_tiempo)))
# Aplicar suavizamiento exponencial simple
modelo_suavizado <- HoltWinters(serie_de_tiempo, beta = FALSE, gamma = FALSE)
modelo_suavizado
Suav_exp <- ses(serie_de_tiempo, h = 15)
autoplot(Suav_exp) + autolayer(fitted(Suav_exp), series="Fitted")
# Instalar y cargar el paquete de suavizamiento exponencial
library(forecast)
# Crear una serie de tiempo con frecuencia diaria
serie_tiempof <- ts(datos_sumados$Calificación, frequency = 2)
mod1 <- HoltWinters(serie_tiempof, seasonal = "additive")
plot(mod1)
adf.test(diff(serie_tiempof))
adf.test(diff(serie_tiempof))
modeloARIMA<-auto.arima(diff(serie_tiempof),  seasonal = FALSE)
summary(modeloARIMA)
modelo_ARIMA <- arima(diff(serie_tiempof), order = c(0,0,2))
n_predicciones <- 10
modpredicciones <- predict(modelo_ARIMA, n.ahead = n_predicciones)
plot(diff(serie_tiempof) , main = "Serie Temporal predicción")
lines(modpredicciones$pred, col = "red", lty = 4)  # Línea de predicción
legend("topright", legend = "Predicción", col = "red", lty = 4)
inicio_zoom <- 300
fin_zoom <- 305
plot(diff(serie_tiempof), main = "Zoom Serie Temporal predicción", xlim = c(inicio_zoom, fin_zoom))
lines(modpredicciones$pred[inicio_zoom:fin_zoom], col = "red", lty = 4)
legend("topright", legend = "Predicción", col = "red", lty = 4)
inicio_zoom <- 292
fin_zoom <- 299
plot(diff(serie_tiempof), main = "Zoom Serie Temporal sin predicción", xlim = c(inicio_zoom, fin_zoom))
lines(modpredicciones$pred[inicio_zoom:fin_zoom], col = "red", lty = 4)
legend("topright", legend = "Predicción", col = "red", lty = 4)
plot(diff(serie_tiempof), main = "Serie Tiempo suavizada Winter Holters vs. Modelo ARIMA")
lines(fitted(modelo_ARIMA), col = "green",  lwd = 0.5)
residuales<-modelo_ARIMA$residuals
qqnorm(residuales)
qqline(residuales)
resultado <- ks.test(residuales, "pnorm", mean(residuales), sd(residuales))
print(resultado)
shapiro.test(residuales)
# Obtén los residuales del modelo ARIMA (reemplaza 'modelo_arima' con tu propio modelo)
residuales <- residuals(modelo_ARIMA)
# Crea un gráfico de dispersión de residuales vs. tiempo
plot(residuales, type = 'o', ylab = 'Residuales', xlab = 'Tiempo', main = 'Gráfico de Residuales')
abline(h = 0, col = 'red', lty = 2)  # Línea horizontal en y = 0
library(prophet)
library(Rcpp)
library(rlang)
df <- data.frame(datos_sumados)
colnames(df) <- c('ds', 'y')
df
m <- prophet(df)
future <- make_future_dataframe(m, periods = 365)
tail(future)
forecast <- predict(m, future)
tail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])
plot(m, forecast)
prophet_plot_components(m, forecast)
dyplot.prophet(m, forecast)
install.packages("rstan")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(knitr)
library(ggplot2)
library(readxl)
library(lubridate)
library(fpp2)
library(zoo)
library(TTR)
library(tseries)
library(aTSA)
library(forecast)
library(ADGofTest)
library(lmtest)
vandalismo <- read_excel("vandalismo.xlsx")
Fecha <- seq(as.Date("2021-01-01"), as.Date("2022-10-26"), by = "days", each = 1)
datos_sumados <- aggregate(Calificación ~ Fecha, data = vandalismo, sum)
grafico <- ggplot(datos_sumados, aes(x = Fecha, y = Calificación)) +
geom_line() +    # Línea para conectar los puntos
geom_point() +   # Puntos en cada fecha
labs(x = "Fecha", y = "Número de Casos", title = "Casos de Vandalismo por Fecha") +
theme_bw()
print(grafico)
# Función de promedio móvil en un intervalo
promedio_movil <- function(datos_sumados, Calificación, intervalo) {
datos_sumados %>%
mutate(promedio = rollmean(Calificación, intervalo, fill = NA))
}
# Calcular promedio móvil con intervalo de 7 días
data_con_promedio <- promedio_movil(datos_sumados, "Calificación", 7)
knitr::kable(head(data_con_promedio, 50), caption = "Base de Datos Vandalismos FLOTA")
#data_con_promedio
# Gráfico de Aproximación en Promedio Móvil
ggplot() +
geom_line(data = datos_sumados, aes(x = Fecha, y = Calificación), color = "blue", linetype = "solid") +
geom_line(data = data_con_promedio, aes(x = Fecha, y = promedio), color = "red", linetype = "dashed") +
labs(title = "Aproximación en Promedio Móvil", x = "Fecha", y = "Valor") +
theme_minimal()
calcular_rezagos <- function(datos_sumados, Calificación, pasos) {
datos_sumados %>%
mutate(across(.cols = Calificación, .fns = list(lag = ~lag(., pasos)), .names = "{col}_lag{pasos}"))
}
# Calcular rezagos de 7 y 14 días
data_con_rezagos <- calcular_rezagos(datos_sumados, "Calificación", 7)
data_con_rezagos <- calcular_rezagos(data_con_rezagos, "Calificación_lag7", 7)
names(data_con_rezagos)
ggplot(data_con_rezagos, aes(x = Fecha)) +
geom_line(aes(y = Calificación, color = "black")) +
geom_line(aes(y = Calificación_lag7, color = "red")) +
labs(title = "Gráfico de Rezagos",
y = "Calificación",
color = "Leyenda") +
scale_color_manual(values = c("Valor original" = "black",
"Rezago 7 días" = "red")) +
theme_minimal()
# Graficar los resultados
ggplot() +
geom_line(data = datos_sumados, aes(x = Fecha, y = Calificación), color = "blue", linetype = "solid") +
geom_line(data = data_con_promedio, aes(x = Fecha, y = promedio), color = "red", linetype = "dashed") +
geom_line(data = data_con_rezagos, aes(x = Fecha, y = Calificación), color = "green", linetype = "dotted") +
geom_line(data = data_con_rezagos, aes(x = Fecha, y = Calificación_lag7), color = "orange", linetype = "dotted") +
labs(title = "Análisis de Variable en el Tiempo", x = "Fecha", y = "Calificación") +
theme_minimal()
# Realizar descomposición de la serie de tiempo
serie_de_tiempo <- ts(datos_sumados$Calificación, frequency = 240)
descomposicion <- decompose(serie_de_tiempo)
# Gráfico de la descomposición
plot(descomposicion)
# Verificar estacionalidad
adf_test <- adf.test(datos_sumados$Calificación)
print(adf_test)
plot(serie_de_tiempo)
abline(reg = lm(serie_de_tiempo ~ time(serie_de_tiempo)))
# Aplicar suavizamiento exponencial simple
modelo_suavizado <- HoltWinters(serie_de_tiempo, beta = FALSE, gamma = FALSE)
modelo_suavizado
Suav_exp <- ses(serie_de_tiempo, h = 15)
autoplot(Suav_exp) + autolayer(fitted(Suav_exp), series="Fitted")
# Instalar y cargar el paquete de suavizamiento exponencial
library(forecast)
# Crear una serie de tiempo con frecuencia diaria
serie_tiempof <- ts(datos_sumados$Calificación, frequency = 2)
mod1 <- HoltWinters(serie_tiempof, seasonal = "additive")
plot(mod1)
mod1 <- HoltWinters(serie_tiempof, seasonal = "additive")
plot(mod1)
adf.test(diff(serie_tiempof))
modeloARIMA<-auto.arima(diff(serie_tiempof),  seasonal = FALSE)
summary(modeloARIMA)
modelo_ARIMA <- arima(diff(serie_tiempof), order = c(0,0,2))
n_predicciones <- 10
modpredicciones <- predict(modelo_ARIMA, n.ahead = n_predicciones)
plot(diff(serie_tiempof) , main = "Serie Temporal predicción")
lines(modpredicciones$pred, col = "red", lty = 4)  # Línea de predicción
legend("topright", legend = "Predicción", col = "red", lty = 4)
inicio_zoom <- 300
fin_zoom <- 305
plot(diff(serie_tiempof), main = "Zoom Serie Temporal predicción", xlim = c(inicio_zoom, fin_zoom))
lines(modpredicciones$pred[inicio_zoom:fin_zoom], col = "red", lty = 4)
legend("topright", legend = "Predicción", col = "red", lty = 4)
inicio_zoom <- 292
fin_zoom <- 299
plot(diff(serie_tiempof), main = "Zoom Serie Temporal sin predicción", xlim = c(inicio_zoom, fin_zoom))
lines(modpredicciones$pred[inicio_zoom:fin_zoom], col = "red", lty = 4)
legend("topright", legend = "Predicción", col = "red", lty = 4)
plot(diff(serie_tiempof), main = "Serie Tiempo suavizada Winter Holters vs. Modelo ARIMA")
lines(fitted(modelo_ARIMA), col = "green",  lwd = 0.5)
residuales<-modelo_ARIMA$residuals
qqnorm(residuales)
qqline(residuales)
resultado <- ks.test(residuales, "pnorm", mean(residuales), sd(residuales))
print(resultado)
shapiro.test(residuales)
# Obtén los residuales del modelo ARIMA (reemplaza 'modelo_arima' con tu propio modelo)
residuales <- residuals(modelo_ARIMA)
# Crea un gráfico de dispersión de residuales vs. tiempo
plot(residuales, type = 'o', ylab = 'Residuales', xlab = 'Tiempo', main = 'Gráfico de Residuales')
abline(h = 0, col = 'red', lty = 2)  # Línea horizontal en y = 0
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(knitr)
library(ggplot2)
library(readxl)
library(lubridate)
library(fpp2)
library(zoo)
library(TTR)
library(tseries)
library(aTSA)
library(forecast)
library(ADGofTest)
library(lmtest)
vandalismo <- read_excel("vandalismo.xlsx")
data_con_promedio
data_con_promedio
head(data_con_promedio, n = 20)
head(data_con_promedio, n = 20)
new_dataprom <- data_con_promedio[c('Fecha', 'promedio')]
colnames(new_dataprom) <- c('ds', 'y')
# ------------
# df <- data.frame(datos_sumados)
# colnames(df) <- c('ds', 'y')
datos_sumados_a <- new_dataprom
head(datos_sumados_a, n=20)
knitr::opts_chunk$set(echo = TRUE)
prophet_plot_components(m, fcst=predict(m, datos_sumados_a)) + theme_bw()
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(knitr)
library(ggplot2)
library(readxl)
library(lubridate)
library(fpp2)
library(zoo)
library(TTR)
library(tseries)
library(aTSA)
library(forecast)
library(ADGofTest)
library(lmtest)
vandalismo <- read_excel("vandalismo.xlsx")
Fecha <- seq(as.Date("2021-01-01"), as.Date("2022-10-26"), by = "days", each = 1)
datos_sumados <- aggregate(Calificación ~ Fecha, data = vandalismo, sum)
grafico <- ggplot(datos_sumados, aes(x = Fecha, y = Calificación)) +
geom_line() +    # Línea para conectar los puntos
geom_point() +   # Puntos en cada fecha
labs(x = "Fecha", y = "Número de Casos", title = "Casos de Vandalismo por Fecha") +
theme_bw()
print(grafico)
# Función de promedio móvil en un intervalo
promedio_movil <- function(datos_sumados, Calificación, intervalo) {
datos_sumados %>%
mutate(promedio = rollmean(Calificación, intervalo, fill = NA))
}
# Calcular promedio móvil con intervalo de 7 días
data_con_promedio <- promedio_movil(datos_sumados, "Calificación", 7)
knitr::kable(head(data_con_promedio, 50), caption = "Base de Datos Vandalismos FLOTA")
#data_con_promedio
# Gráfico de Aproximación en Promedio Móvil
ggplot() +
geom_line(data = datos_sumados, aes(x = Fecha, y = Calificación), color = "blue", linetype = "solid") +
geom_line(data = data_con_promedio, aes(x = Fecha, y = promedio), color = "red", linetype = "dashed") +
labs(title = "Aproximación en Promedio Móvil", x = "Fecha", y = "Valor") +
theme_minimal()
calcular_rezagos <- function(datos_sumados, Calificación, pasos) {
datos_sumados %>%
mutate(across(.cols = Calificación, .fns = list(lag = ~lag(., pasos)), .names = "{col}_lag{pasos}"))
}
# Calcular rezagos de 7 y 14 días
data_con_rezagos <- calcular_rezagos(datos_sumados, "Calificación", 7)
data_con_rezagos <- calcular_rezagos(data_con_rezagos, "Calificación_lag7", 7)
names(data_con_rezagos)
ggplot(data_con_rezagos, aes(x = Fecha)) +
geom_line(aes(y = Calificación, color = "black")) +
geom_line(aes(y = Calificación_lag7, color = "red")) +
labs(title = "Gráfico de Rezagos",
y = "Calificación",
color = "Leyenda") +
scale_color_manual(values = c("Valor original" = "black",
"Rezago 7 días" = "red")) +
theme_minimal()
# Graficar los resultados
ggplot() +
geom_line(data = data_con_rezagos, aes(x = Fecha, y = Calificación), color = "green", linetype = "dotted") +
geom_line(data = data_con_rezagos, aes(x = Fecha, y = Calificación_lag7), color = "orange", linetype = "dotted") +
geom_line(data = datos_sumados, aes(x = Fecha, y = Calificación), color = "blue", linetype = "solid") +
geom_line(data = data_con_promedio, aes(x = Fecha, y = promedio), color = "red", linetype = "dashed") +
labs(title = "Análisis de Variable en el Tiempo", x = "Fecha", y = "Calificación") +
theme_minimal()
# Realizar descomposición de la serie de tiempo
serie_de_tiempo <- ts(datos_sumados$Calificación, frequency = 240)
descomposicion <- decompose(serie_de_tiempo)
# Gráfico de la descomposición
plot(descomposicion)
# Verificar estacionalidad
adf_test <- adf.test(datos_sumados$Calificación)
print(adf_test)
plot(serie_de_tiempo)
abline(reg = lm(serie_de_tiempo ~ time(serie_de_tiempo)))
# Aplicar suavizamiento exponencial simple
modelo_suavizado <- HoltWinters(serie_de_tiempo, beta = FALSE, gamma = FALSE)
modelo_suavizado
Suav_exp <- ses(serie_de_tiempo, h = 15)
autoplot(Suav_exp) + autolayer(fitted(Suav_exp), series="Fitted")
# Instalar y cargar el paquete de suavizamiento exponencial
library(forecast)
# Crear una serie de tiempo con frecuencia diaria
serie_tiempof <- ts(datos_sumados$Calificación, frequency = 2)
mod1 <- HoltWinters(serie_tiempof, seasonal = "additive")
plot(mod1)
mod1
adf.test(diff(serie_tiempof))
adf.test(diff(serie_tiempof))
modeloARIMA<-auto.arima(diff(serie_tiempof),  seasonal = FALSE)
summary(modeloARIMA)
modelo_ARIMA <- arima(diff(serie_tiempof), order = c(0,0,2))
n_predicciones <- 10
modpredicciones <- predict(modelo_ARIMA, n.ahead = n_predicciones)
plot(diff(serie_tiempof) , main = "Serie Temporal predicción")
lines(modpredicciones$pred, col = "red", lty = 4)  # Línea de predicción
legend("topright", legend = "Predicción", col = "red", lty = 4)
inicio_zoom <- 300
fin_zoom <- 305
plot(diff(serie_tiempof), main = "Zoom Serie Temporal predicción", xlim = c(inicio_zoom, fin_zoom))
lines(modpredicciones$pred[inicio_zoom:fin_zoom], col = "red", lty = 4)
legend("topright", legend = "Predicción", col = "red", lty = 4)
inicio_zoom <- 292
fin_zoom <- 299
plot(diff(serie_tiempof), main = "Zoom Serie Temporal sin predicción", xlim = c(inicio_zoom, fin_zoom))
lines(modpredicciones$pred[inicio_zoom:fin_zoom], col = "red", lty = 4)
legend("topright", legend = "Predicción", col = "red", lty = 4)
plot(diff(serie_tiempof), main = "Serie Tiempo suavizada Winter Holters vs. Modelo ARIMA")
lines(fitted(modelo_ARIMA), col = "green",  lwd = 0.5)
residuales<-modelo_ARIMA$residuals
qqnorm(residuales)
qqline(residuales)
resultado <- ks.test(residuales, "pnorm", mean(residuales), sd(residuales))
print(resultado)
shapiro.test(residuales)
# Obtén los residuales del modelo ARIMA (reemplaza 'modelo_arima' con tu propio modelo)
residuales <- residuals(modelo_ARIMA)
# Crea un gráfico de dispersión de residuales vs. tiempo
plot(residuales, type = 'o', ylab = 'Residuales', xlab = 'Tiempo', main = 'Gráfico de Residuales')
abline(h = 0, col = 'red', lty = 2)  # Línea horizontal en y = 0
library(prophet)
library(Rcpp)
library(rlang)
head(data_con_promedio, n = 20)
new_dataprom <- data_con_promedio[c('Fecha', 'promedio')]
colnames(new_dataprom) <- c('ds', 'y')
# ------------
# df <- data.frame(datos_sumados)
# colnames(df) <- c('ds', 'y')
datos_sumados_a <- new_dataprom
head(datos_sumados_a, n=20)
m <- prophet(datos_sumados_a, yearly.seasonality = 13, weekly.seasonality = FALSE, daily.seasonality = FALSE, seasonality.mode = 'additive')
future <- make_future_dataframe(m, periods = 2*365, freq = 'day')
forecast <- predict(m, future)
plot(m, forecast)  + theme_bw()
prophet_plot_components(m, fcst=predict(m, datos_sumados_a)) + theme_bw()
library(prophet)
library(Rcpp)
library(rlang)
inicio_zoom <- 300
fin_zoom <- 350
plot(diff(serie_tiempof), main = "Zoom Serie Temporal predicción", xlim = c(inicio_zoom, fin_zoom))
lines(modpredicciones$pred[inicio_zoom:fin_zoom], col = "red", lty = 4)
legend("topright", legend = "Predicción", col = "red", lty = 4)
prophet_plot_components(m, fcst=predict(m, datos_sumados_a)) + theme_bw();
